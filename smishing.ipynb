{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"스미싱 모델 성능 평가.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"WY9deXN3W8D4","colab_type":"text"},"source":["위에서부터 순서대로 실행하면 되느니라"]},{"cell_type":"code","metadata":{"id":"vglMrrb_vyqd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"executionInfo":{"status":"ok","timestamp":1593777732230,"user_tz":-540,"elapsed":24219,"user":{"displayName":"박세환","photoUrl":"","userId":"09044623774325048638"}},"outputId":"5feb4e2c-8ab2-4e9e-d89e-6bb602a7e038"},"source":["# Drive Mount\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mcJWyethwO1L","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":90},"executionInfo":{"status":"ok","timestamp":1593777736547,"user_tz":-540,"elapsed":3474,"user":{"displayName":"박세환","photoUrl":"","userId":"09044623774325048638"}},"outputId":"8a58fb80-d2b3-46b5-8a4d-30f4e3947548"},"source":["# Module Import\n","from google.colab import drive\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import csv\n","import collections\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer \n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.layers import SimpleRNN, Embedding, Dense, LSTM, Dropout, Flatten\n","from tensorflow.keras.layers import GlobalMaxPooling1D, MaxPooling1D, Conv1D, Conv2D, Conv3D, MaxPooling2D\n","from tensorflow.keras.layers import BatchNormalization, Activation, Bidirectional, TimeDistributed\n","from tensorflow.keras.models import Sequential\n","\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from keras.models import load_model\n","from keras import regularizers\n","from keras import backend as K\n","from keras import callbacks\n","\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.metrics import mean_squared_error,roc_auc_score,precision_score\n","from sklearn.metrics import f1_score, recall_score, precision_score, scorer\n","import sklearn.utils.multiclass\n","\n","class Metrics(tf.keras.callbacks.Callback):\n","    def __init__(self, validation):   \n","        super(Metrics, self).__init__()\n","        self.validation = validation    \n","        print('validation shape', len(self.validation[0]))\n","        \n","    def on_train_begin(self, logs={}):        \n","        self.val_f1s = []\n","        self.val_recalls = []\n","        self.val_precisions = []\n","     \n","    def on_epoch_end(self, epoch, logs={}):\n","        val_targ = self.validation[1]   \n","        val_predict = (np.asarray(self.model.predict(self.validation[0]))).round()\n","\n","        val_f1 = f1_score(val_targ, val_predict)\n","        val_recall = recall_score(val_targ, val_predict)         \n","        val_precision = precision_score(val_targ, val_predict)\n","        \n","        self.val_f1s.append(round(val_f1, 6))\n","        self.val_recalls.append(round(val_recall, 6))\n","        self.val_precisions.append(round(val_precision, 6))\n"," \n","        print(f' — val_f1: {val_f1} — val_precision: {val_precision}, — val_recall: {val_recall}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n","  warnings.warn(message, FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"4xr8_qZOv05P","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"status":"ok","timestamp":1593777770136,"user_tz":-540,"elapsed":29827,"user":{"displayName":"박세환","photoUrl":"","userId":"09044623774325048638"}},"outputId":"b68231da-5d34-4630-857c-d7e24e2c44f3"},"source":["# morph token data load\n","data = pd.read_csv('/content/drive/Shared drives/BigData/processed_data/labeled_data.csv',index_col=0)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (89,90,220,268,269,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666) have mixed types.Specify dtype option on import or set low_memory=False.\n","  interactivity=interactivity, compiler=compiler, result=result)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"eYyr9BZFKKDH","colab_type":"code","colab":{}},"source":["# space token data\n","data = pd.read_csv('/content/drive/Shared drives/BigData/processed_data/space_token_labeled_data.csv',index_col=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nAQcYTWYiHKc","colab_type":"code","colab":{}},"source":["#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","#   1. 데이터 전처리\n","#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","# remove nan and to List\n","data_list = []\n","for d in data.values.tolist():\n","    data_list.append(list(str(x) for x in d[1:] if pd.notnull(x)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qihZ9Ux8ikEJ","colab_type":"code","colab":{}},"source":["#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","#   2. 데이터 토큰화\n","#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","vocab_size = 994 # 994인 이유는 빈도수 2이상인 단어가 994개\n","tokenizer = Tokenizer(num_words=vocab_size)\n","tokenizer.fit_on_texts(data_list)\n","sequences = tokenizer.texts_to_sequences(data_list)\n","max_len = max(map(len, data_list))\n","smishing_text = pad_sequences(sequences, maxlen=max_len)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oGvGGV4dPm0r","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":87},"executionInfo":{"status":"ok","timestamp":1593778359322,"user_tz":-540,"elapsed":4766,"user":{"displayName":"박세환","photoUrl":"","userId":"09044623774325048638"}},"outputId":"a1c4609c-53b4-4032-c6f1-60f1f393092b"},"source":["#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","#   3. 학습용 데이터 분류\n","#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","processed_data = pd.concat([data['smishing'], pd.DataFrame(smishing_text)], axis=1)\n","\n","smishing_data = processed_data[processed_data['smishing'] == 1]\n","normal_data = processed_data[processed_data['smishing'] == 0]\n","\n","num_of_smishing = len(smishing_data)\n","num_of_normal = len(normal_data)\n","\n","smishing_train_end = 18000\n","normal_train_end = 2400\n","\n","smishing_validation_end = int(num_of_smishing*0.8)\n","normal_validation_end = int(num_of_normal*0.8)\n","\n","# train data\n","train_data = pd.concat([\n","                        smishing_data[:int(smishing_train_end*0.8)], \n","                        normal_data[:int(normal_train_end*0.8)]\n","                        ]).sample(frac=1).reset_index(drop=True)\n","\n","# validation data\n","val_data = pd.concat([\n","                      smishing_data[int(smishing_train_end*0.8):2400], \n","                      normal_data[int(normal_train_end*0.8):20000]\n","                      ]).sample(frac=1).reset_index(drop=True)\n","\n","# test data\n","test_data = pd.concat([\n","                       smishing_data[2400:], \n","                       normal_data[20000:]\n","                       ]).sample(frac=1).reset_index(drop=True)\n","\n","x_train = np.array(train_data.iloc[:,1:])\n","y_train = np.array(train_data['smishing'])\n","\n","x_val = np.array(val_data.iloc[:,1:])\n","y_val = np.array(val_data['smishing'])\n","\n","x_test = np.array(test_data.iloc[:,1:])\n","y_test = np.array(test_data['smishing'])\n","\n","print(\"Normal Data\")\n","print(f'{normal_train_end} : {int(num_of_normal*0.2)} : {int(num_of_normal*0.2)}')\n","print(\"Smishing Data\")\n","print(f'{smishing_train_end} : {int(num_of_smishing*0.2)} : {int(num_of_smishing*0.2)}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Normal Data\n","2400 : 55448 : 55448\n","Smishing Data\n","18000 : 3740 : 3740\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qltx33MnhvSe","colab_type":"code","colab":{}},"source":["#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","#   4.1 모델 구축 Embedding - CNN - LSTM\n","#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","model = Sequential()\n","model.add(Embedding(vocab_size, 128, input_length=max_len))\n","model.add(Dropout(0.25))\n","model.add(Conv1D(128,\n","                 5,\n","                 padding='valid',\n","                 activation='relu',\n","                 strides=1))\n","model.add(MaxPooling1D(pool_size=4))\n","model.add(Bidirectional(LSTM(32)))\n","model.add(Flatten())\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9jP1GxkO3JCS","colab_type":"code","colab":{}},"source":["#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","#   4.2 모델 구축 Embedding - CNN\n","#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","model = Sequential()\n","model.add(Embedding(vocab_size, 64, input_length=max_len))\n","model.add(Dropout(0.25))\n","model.add(Conv1D(64,\n","                 5,\n","                 padding='valid',\n","                 activation='relu',\n","                 strides=1))\n","model.add(MaxPooling1D(pool_size=4))\n","model.add(Flatten())\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mDfTIGEJpq5t","colab_type":"code","colab":{}},"source":["#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","#   4.3 모델 구축 Embedding - LSTM\n","#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","model = Sequential()\n","model.add(Embedding(vocab_size, 64, input_length=max_len))\n","model.add(Bidirectional(LSTM(32)))\n","model.add(Flatten())\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SR5ZsWNQROXl","colab_type":"code","colab":{}},"source":["#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","#   5. 학습\n","#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","es = tf.keras.callbacks.EarlyStopping(monitor='val_loss',mode='min', verbose=1, patience=2)\n","mc = tf.keras.callbacks.ModelCheckpoint('best_model.h5',monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n","\n","# fit the mode\n","hist = model.fit(\n","    x_train, \n","    y_train,\n","    validation_data=(x_val,y_val), \n","    epochs=20,\n","    batch_size=512,\n","    callbacks=[Metrics(validation=(x_val, y_val))],\n","    verbose=1\n",")\n","\n","y_pred = model.predict(x_test, verbose=1).flatten().round()\n","print(classification_report(y_test, y_pred, target_names=['class 0', 'class 1']))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IAO7qj3Kq66Z","colab_type":"code","colab":{}},"source":["#model.save('/content/drive/Shared drives/BigData/smishing_CNN+BILSM_model.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NY3yj-RWB_Rq","colab_type":"code","colab":{}},"source":["# install LightBGM\n","!git clone https://github.com/Microsoft/LightGBM\n","!cd LightGBM\n","!mkdir build\n","!cmake -DUSE_GPU=1\n","!make -j$(nproc)\n","!sudo apt-get -y install python-pip\n","!sudo -H pip install setuptools pandas numpy scipy scikit-learn -U\n","%cd /content/LightGBM/python-package\n","!sudo python setup.py install\n","!pip3 uninstall scikit-learn\n","!pip3 install scikit-learn==0.21.3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3hQTLeX062hY","colab_type":"code","colab":{}},"source":["from scipy.stats import randint as sp_randint\n","from scipy.stats import uniform as sp_uniform\n","param_test ={'num_leaves': sp_randint(6, 50), \n","             'min_child_samples': sp_randint(100, 500), \n","             'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n","             'subsample': sp_uniform(loc=0.2, scale=0.8), \n","             'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n","             'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n","             'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dI3hK2vX656u","colab_type":"code","colab":{}},"source":["n_HP_points_to_test = 100\n","\n","import lightgbm as lgb\n","from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n","\n","#n_estimators is set to a \"large value\". The actual number of trees build will depend on early stopping and 5000 define only the absolute maximum\n","clf = lgb.LGBMClassifier(max_depth=-1, random_state=314, silent=True, metric='None', n_jobs=4, n_estimators=5000)\n","gs = RandomizedSearchCV(\n","    estimator=clf, param_distributions=param_test, \n","    n_iter=n_HP_points_to_test,\n","    scoring='roc_auc',\n","    cv=3,\n","    refit=True,\n","    random_state=314,\n","    verbose=True)\n","\n","opt_parameters = {'colsample_bytree': 0.9234, 'min_child_samples': 399, 'min_child_weight': 0.1, 'num_leaves': 13, 'reg_alpha': 2, 'reg_lambda': 5, 'subsample': 0.855}\n","\n","clf_sw = lgb.LGBMClassifier(**clf.get_params())\n","#set optimal parameters\n","clf_sw.set_params(**opt_parameters)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rSkNn4Is7u-t","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"5d6128a8-121f-4dc7-b23f-6bdb1fbd94c8"},"source":["import lightgbm as lgb\n","from sklearn.metrics import f1_score\n","\n","def lgb_f1_score(y_hat, data):\n","    y_true = data.get_label()\n","    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n","    return 'f1', f1_score(y_true, y_hat), True\n","\n","evals_result = {}\n","\n","X_train = StandardScaler().fit_transform(x_train)\n","X_val = StandardScaler().fit_transform(x_val)\n","X_test = StandardScaler().fit_transform(x_test)\n","\n","Y_train = y_train\n","Y_val = y_val\n","Y_test = y_test\n","\n","dtrain = lgb.Dataset(X_train, Y_train)\n","dvalid = lgb.Dataset(X_val, Y_val)\n","\n","#Specifying the parameter\n","params={}\n","params['learning_rate']=0.03\n","params['boosting_type']='gbdt' #GradientBoostingDecisionTree\n","params['objective']='binary' #Binary target feature\n","params['metric']='binary_logloss' #metric for binary classification\n","\n","print(\"Train Start...\")\n","#train the model \n","clf=lgb.train(\n","    params, \n","    dtrain,\n","    10, \n","    valid_sets = dvalid,\n","    feval=lgb_f1_score, \n","    evals_result=evals_result\n",") #train the model on 100 epocs"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train Start...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gn8JU_nSq8r5","colab_type":"code","colab":{}},"source":["#prediction on the test set\n","Y_pred=clf.predict(X_test)\n","\n","#rounding the values\n","Y_pred=Y_pred.round(0)\n","\n","#converting from float to integer\n","Y_pred=Y_pred.astype(int)\n","\n","print(classification_report(Y_test, Y_pred, target_names=['class 0', 'class 1']))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VSz8vZimV8uK","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score, recall_score, precision_score\n","import numpy as np\n","import os\n","\n","\n","class Metrics(tf.keras.callbacks.Callback):\n","    def __init__(self, valid_data):\n","        super(Metrics, self).__init__()\n","        self.validation_data = valid_data\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        logs = logs or {}\n","        val_predict = np.argmax(self.model.predict(self.validation_data[0]), -1)\n","        val_targ = self.validation_data[1]\n","        if len(val_targ.shape) == 2 and val_targ.shape[1] != 1:\n","            val_targ = np.argmax(val_targ, -1)\n","\n","        _val_f1 = f1_score(val_targ, val_predict, average='macro')\n","        _val_recall = recall_score(val_targ, val_predict, average='macro')\n","        _val_precision = precision_score(val_targ, val_predict, average='macro')\n","\n","        logs['val_f1'] = _val_f1\n","        logs['val_recall'] = _val_recall\n","        logs['val_precision'] = _val_precision\n","        print(\" — val_f1: %f — val_precision: %f — val_recall: %f\" % (_val_f1, _val_precision, _val_recall))\n","        return\n","\n","\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n","x_train, x_test = x_train / 255.0, x_test / 255.0\n","\n","x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=10000, random_state=32)\n","\n","# LeNet-5\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Input(shape=(32, 32, 3)),\n","    tf.keras.layers.Conv2D(6, 5, activation='relu'),\n","    tf.keras.layers.AveragePooling2D(),\n","    tf.keras.layers.Conv2D(16, 5, activation='relu'),\n","    tf.keras.layers.AveragePooling2D(),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(120, activation='relu'),\n","    tf.keras.layers.Dropout(0.2),\n","    tf.keras.layers.Dense(84, activation='relu'),\n","    tf.keras.layers.Dropout(0.2),\n","    tf.keras.layers.Dense(10, activation='softmax')\n","])\n","\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","if not os.path.exists('./checkpoints'):\n","    os.makedirs('./checkpoints')\n","\n","#Save the model according to val\n","ck_callback = tf.keras.callbacks.ModelCheckpoint('./checkpoints/weights.{epoch:02d}-{val_f1:.4f}.hdf5',\n","                                                 monitor='val_f1', \n","                                                 mode='max', verbose=2,\n","                                                 save_best_only=True,\n","                                                 save_weights_only=True)\n","tb_callback = tf.keras.callbacks.TensorBoard(log_dir='./logs', profile_batch=0)\n","model.fit(x_train, y_train,\n","          validation_data=(x_val, y_val),\n","          epochs=100,\n","          callbacks=[Metrics(valid_data=(x_val, y_val)),\n","                     ck_callback,\n","                     tb_callback])"],"execution_count":null,"outputs":[]}]}